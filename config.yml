# config.yml
logging_level: DEBUG
allowed_file_extensions: [".pdf", ".doc", ".docx", ".jpg", ".jpeg", ".tiff", ".png"]
allowed_file_size_limit: 10485760  # 10 MB in bytes
processed_dir: "./data/processed_dir"
#model_path: "models/LLM/Llama-3.2-11B-Vision-Instruct.Q8_0.gguf"
model_path: "external/LLM/Llama-3.2-3B-Instruct-Q8_0.gguf"
#model_path: "external/LLM/BioMistral-ggml-model-Q8_0.gguf"
# model_path: "external/LLM/MiniCPM-o-2_6-7.6B-Q8_0.gguf"
model_type_is_vision: False

llama_server_binary_path: "./external/llama.cpp/bin/llama-server"
llama_server_host: 127.0.0.1
#llama_server_host: 10.96.84.174
llama_server_port: 8080
llama_server_endpoint: /completion
max_embedding_input_length: 1024
embedding_hidden_size: 4096
is_production: false
launch_llama_server: true
llama_server_ui_url: http://127.0.0.1:8080

# Qdrant configuration
qdrant:
  host: "localhost"
  port: 6333
  collection_name: "default_collection"
  vector_size: 4096

# Database configuration
database_url: "sqlite:///./jobs.db"

#cpu or gpu
use_gpu: false

frontend_backend_base_url: "http://127.0.0.1:8000"
backend_base_url: "http://127.0.0.1:8000"